{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DuYqvtFQz7t"
   },
   "source": [
    "# 数据采集\n",
    "\n",
    "1. 本研究利用现有的自动化网页点击脚本，针对在线文章进行关键词相关的文本数据抓取。该脚本专门设计用于分析特定关键词在近年学术文献中的研究趋势和发展模式。\n",
    "\n",
    "2. 为了深入理解铁路建设与殖民权力、以及铁路与反殖民斗争之间的学术讨论和研究进展，我们在Google Scholar上以“railway construction” AND “colonial power”、“colonial railways” OR “anti-colonial struggle”为关键词进行了系统的文献检索。这项检索工作旨在揭示近年来在这些领域内的研究重点和趋势。\n",
    "\n",
    "3. 鉴于Google Scholar的搜索限制，我们的检索起始年份设定为1900年，并且每个主题的搜索结果限制在100页以内。尽管存在这些限制，我们还是成功地为两个主题分别收集了1000条和999条文本信息，确保了数据的丰富性和多样性。\n",
    "\n",
    "4. 收集的文本信息主要包括相关学术文章的标题，这些标题为我们提供了对各研究主题核心议题和研究方向的初步了解。\n",
    "\n",
    "5. 成功采集了针对两个主题的文本信息，分别获得1000条和999条数据。经过分词处理进行了词频统计，并通过词云图直观展现了研究领域的关键词分布。希望这些分析了解学术讨论中的热点和趋势。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. 安装需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3eBfDJqHQfP4"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package, version):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{package}=={version}\"])\n",
    "\n",
    "# 需要安装的包及其版本\n",
    "required_packages = {\n",
    "    \"selenium\": \"4.10.0\",\n",
    "    \"tqdm\": \"4.65.0\",\n",
    "    \"pyautogui\": \"0.9.53\",\n",
    "    \"beautifulsoup4\": \"4.12.2\",\n",
    "    \"pandas\": \"2.0.1\",\n",
    "    \"openpyxl\": \"3.1.2\",\n",
    "    \"nltk\": \"3.8.1\",\n",
    "    \"wordcloud\": \"1.8.2.2\",\n",
    "    \"matplotlib\": \"3.7.1\"\n",
    "}\n",
    "\n",
    "for package, version in required_packages.items():\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        install(package, version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ozf4QeFP2YH"
   },
   "source": [
    "\n",
    "#2. 开始年份不得低于1900，采集页数最大只能100页（受谷歌学术限制）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "cekaSnMMN_zV",
    "outputId": "7e03c932-ed36-412f-c923-8c0e75e3ae1b"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-76d6b15b0b49>, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-76d6b15b0b49>\"\u001b[0;36m, line \u001b[0;32m61\u001b[0m\n\u001b[0;31m    options.add_argument(\"--headless\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title 开始采集\n",
    "\n",
    "是否按年份排序 = False #@param {type:\"boolean\"}\n",
    "搜索关键词 = \"\\\"railway construction\\\" AND \\\"colonial power\\\"\" #@param {type:\"string\"}\n",
    "开始年份 = \"1950\" #@param {type:\"string\"}\n",
    "结束年份 = \"2024\" #@param {type:\"string\"}\n",
    "采集页数 = \"1\" #@param {type:\"string\"}\n",
    "\n",
    "if 是否按年份排序 == True:\n",
    "  isYear = 'y'\n",
    "else:\n",
    "  isYear = 'n'\n",
    "keywd = 搜索关键词\n",
    "st_y = 开始年份\n",
    "ed_y = 结束年份\n",
    "c_page = 采集页数\n",
    "\n",
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pyautogui\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "import pyperclip\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import openpyxl\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "class Errors(Enum):\n",
    "    SUCCESS         = '成功'\n",
    "    SERVER_ERROR    = '服务器错误'\n",
    "\n",
    "\n",
    "class Scholar:\n",
    "    def __init__(self, out_filepath) -> None:\n",
    "        self.out_filepath = out_filepath\n",
    "        if not os.path.exists(self.out_filepath):\n",
    "            os.mkdir(self.out_filepath)\n",
    "        self.driver = None\n",
    "        self.results = []\n",
    "\n",
    "    def start_browser(self, wait_time=10):\n",
    "        # 创建ChromeOptions对象\n",
    "        options = Options()\n",
    "        # 启用无头模式\n",
    "        # options.add_argument(\"--headless\")\n",
    "        # 启用无痕模式\n",
    "        options.add_argument(\"--incognito\")\n",
    "        options.add_argument(\"--disable-domain-reliability\")\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        options.add_argument(\"--disable-client-side-phishing-detection\")\n",
    "        options.add_argument(\"--no-first-run\")\n",
    "        options.add_argument(\"--use-fake-device-for-media-stream\")\n",
    "        options.add_argument(\"--autoplay-policy=user-gesture-required\")\n",
    "        options.add_argument(\"--disable-features=ScriptStreaming\")\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--disable-popup-blocking\")\n",
    "        options.add_argument(\"--disable-save-password-bubble\")\n",
    "        options.add_argument(\"--mute-audio\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "        options.add_argument(\"--disable-software-rasterizer\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        options.add_argument(\"--disable-webgl\")\n",
    "        options.add_argument(\"--allow-running-insecure-content\")\n",
    "        options.add_argument(\"--no-default-browser-check\")\n",
    "        options.add_argument(\"--disable-full-form-autofill-ios\")\n",
    "        options.add_argument(\"--disable-autofill-keyboard-accessory-view[8]\")\n",
    "        options.add_argument(\"--disable-single-click-autofill\")\n",
    "        options.add_argument(\"--ignore-certificate-errors\")\n",
    "        options.add_argument(\"--disable-infobars\")\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        options.add_argument(\"--disable-blink-features\")\n",
    "        # 禁用实验性QUIC协议\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-quic\"])\n",
    "        # 创建Chrome浏览器实例\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "        # 等待页面加载完成\n",
    "        self.driver.implicitly_wait(wait_time)\n",
    "\n",
    "    def __search_onepage(self):\n",
    "        \"\"\"爬取当前页面文章的的信息\"\"\"\n",
    "        results = []\n",
    "\n",
    "        if not self.check_element_exist(check_type='ID', value='gs_res_ccl_mid'):\n",
    "            print('>> 当前页面不存在文章列表')\n",
    "            return []\n",
    "        gs_scl = self.driver.find_element(by=By.ID, value='gs_res_ccl_mid').find_elements(by=By.CLASS_NAME, value='gs_scl')\n",
    "        for i, item in tqdm(enumerate(gs_scl)):\n",
    "            gs_rt = item.find_element(by=By.CLASS_NAME, value='gs_rt')\n",
    "            gs_a = item.find_element(by=By.CLASS_NAME, value='gs_a')\n",
    "            gs_rt_a = gs_rt.find_element(by=By.TAG_NAME, value='a') if self.check_element_exist(check_type='TAG_NAME', value='a', source=gs_rt.get_attribute('innerHTML')) else None\n",
    "            publisher_info = gs_a.text.strip().replace('\\n', '')\n",
    "            # 论文标题\n",
    "            title = gs_rt.text.strip().replace('\\n', '').split(']')[-1].strip()\n",
    "            # 论文链接\n",
    "            href = gs_rt_a.get_attribute('href') if gs_rt_a else ''\n",
    "            # 发表年份\n",
    "            year = re.findall(r'\\d{4}', publisher_info)\n",
    "            year = year[-1] if year else -1\n",
    "\n",
    "            # print(f'[{i}] {title} => {href} => {publisher_info} => {year}')\n",
    "            results.append({'title': title, 'href':href, 'year': year})\n",
    "        return results\n",
    "\n",
    "    def check_element_exist(self, value, check_type='CLASS_NAME', source=None) -> bool:\n",
    "        \"\"\"检查页面是否存在指定元素\"\"\"\n",
    "        page_source = source if source else self.driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "        if check_type == 'ID':\n",
    "            return len(soup.find_all(id=value)) != 0\n",
    "        elif check_type == 'CLASS_NAME':\n",
    "            return len(soup.find_all(class_=value)) != 0\n",
    "        elif check_type == 'TAG_NAME':\n",
    "            return len(soup.find_all(value)) != 0\n",
    "        elif check_type == 'FULL':\n",
    "            return value in page_source\n",
    "        else:\n",
    "            print(f'>> 检查条件[{check_type}]不对')\n",
    "        return False\n",
    "\n",
    "    def check_captcha(self) -> bool:\n",
    "        \"\"\"检查是否需要人机验证；一个是谷歌学术的、一个是谷歌搜索的\"\"\"\n",
    "        return self.check_element_exist(check_type='ID', value='gs_captcha_f') or \\\n",
    "               self.check_element_exist(check_type='ID', value='captcha-form')\n",
    "\n",
    "    def process_error(self, error: Errors) -> bool:\n",
    "        \"\"\"尽可能尝试解决错误\"\"\"\n",
    "        success = False\n",
    "        if error == Errors.SERVER_ERROR:\n",
    "            pass\n",
    "\n",
    "        return success\n",
    "\n",
    "    def check_error(self, try_solve = True) -> Errors:\n",
    "        \"\"\"检查当前页面是否出错\"\"\"\n",
    "        error = Errors.SUCCESS\n",
    "        if self.check_element_exist(check_type='FULL', value='服务器错误'):\n",
    "            error = Errors.SERVER_ERROR\n",
    "\n",
    "        # 尝试解决错误\n",
    "        if try_solve and error != Errors.SUCCESS:\n",
    "            error = Errors.SUCCESS if self.process_error(error) else error\n",
    "        return error\n",
    "\n",
    "    def __scroll2bottom(self):\n",
    "        # 将滚动条移动到页面的底部\n",
    "        self.driver.switch_to.default_content()\n",
    "        js = \"var q=document.documentElement.scrollTop=100000\"\n",
    "        self.driver.execute_script(js)\n",
    "\n",
    "    def search(self, keywords, sort_bydate=False, as_ylo='', as_yhi='', max_pages=100, delay=0):\n",
    "        keywords = keywords.replace(' ', '+')\n",
    "        sort_bydate = 'scisbd=1' if sort_bydate else ''\n",
    "        url = f'https://scholar.google.com/scholar?{sort_bydate}&hl=zh-CN&as_sdt=0%2C5&q={keywords}&btnG=&as_ylo={as_ylo}&as_yhi={as_yhi}'\n",
    "        # 打开Google Scholar网站\n",
    "        self.driver.get(url)\n",
    "\n",
    "        for _ in tqdm(range(1, max_pages+1), desc='搜索中'):\n",
    "            while self.check_captcha():\n",
    "                pyautogui.alert(title='状态异常', text='请手动完成人机验证后，点击“已完成”', button='已完成')\n",
    "                self.driver.refresh()\n",
    "                time.sleep(2)\n",
    "            if self.check_error() != Errors.SUCCESS:\n",
    "                if pyautogui.confirm(text='请检查页面出现了什么问题;\\n解决后，点击“确定”将会重试;\\n否则，点击“取消”提前结束脚本;', title='状态异常', buttons=['确定', '取消']) == '取消':\n",
    "                    print('>> 提前结束')\n",
    "                    break\n",
    "                time.sleep(2)\n",
    "\n",
    "            onepage = self.__search_onepage()\n",
    "            if not onepage:\n",
    "                print('>> 当前页为空, 重试')\n",
    "                self.driver.refresh()\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "\n",
    "            self.results.extend(onepage)\n",
    "\n",
    "            if not self.check_element_exist(check_type='CLASS_NAME', value='gs_ico_nav_next'):\n",
    "                print('>> 全部结束')\n",
    "                break\n",
    "            self.__scroll2bottom()\n",
    "            time.sleep(0.1)\n",
    "            self.driver.find_element(by=By.CLASS_NAME, value=\"gs_ico_nav_next\").click()\n",
    "            time.sleep(delay)\n",
    "\n",
    "        total_num = self.driver.find_element(by=By.ID, value='gs_ab_md').find_element(by=By.CLASS_NAME, value='gs_ab_mdw').text.strip()  # .replace('\\n', '').split(',')[:-1]\n",
    "        open(os.path.join(self.out_filepath, 'total_num.txt'), 'w+').write(''.join(total_num))\n",
    "\n",
    "\n",
    "        return self.results\n",
    "\n",
    "    def close_browser(self):\n",
    "        # 关闭浏览器\n",
    "        self.driver.quit()\n",
    "\n",
    "    def save_file(self, filename='scholar.xlsx', nodup=False):\n",
    "        unique_data = self.results\n",
    "        if nodup:\n",
    "            # 根据href字段进行去重\n",
    "            unique_data = [dict(t) for t in {tuple(d.items()) for d in unique_data}]\n",
    "        print(f'>> 去重效果：{len(self.results)} => {len(unique_data)}')\n",
    "        try:\n",
    "            pd.DataFrame(unique_data).dropna().reset_index(drop=True).to_excel(os.path.join(self.out_filepath, filename), index=False)\n",
    "            # 加载Excel文件并设置字体样式\n",
    "            workbook = openpyxl.load_workbook(os.path.join(self.out_filepath, filename))\n",
    "            worksheet = workbook.active\n",
    "            for column in worksheet.columns:\n",
    "                column[0].font = openpyxl.styles.Font(bold=True)\n",
    "            # 设置列宽\n",
    "            worksheet.column_dimensions['A'].width = 30  # 调整第一列（标题列）宽度\n",
    "            worksheet.column_dimensions['B'].width = 100  # 调整第二列（href列）宽度\n",
    "            workbook.save(os.path.join(self.out_filepath, filename))\n",
    "        except Exception as e:\n",
    "            if pyautogui.confirm(text=f'文件保存失败[{str(e)}]\\n点击“确定”将内容复制到剪切板;\\n否则, 点击“取消”直接结束脚本;', title='文件保存失败', buttons=['确定', '取消']) == '确定':\n",
    "                pyperclip.copy(str(unique_data))\n",
    "\n",
    "\n",
    "\n",
    "    def statistical_information(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class AnalyzeDraw:\n",
    "    def __init__(self, out_filepath, filename='scholar.xlsx') -> None:\n",
    "        self.out_filepath = out_filepath\n",
    "        if not os.path.exists(self.out_filepath):\n",
    "            os.mkdir(self.out_filepath)\n",
    "        self.filename = filename\n",
    "        self.df = pd.read_excel(os.path.join(self.out_filepath, filename))\n",
    "\n",
    "    def draw_wordcloud(self):\n",
    "        \"\"\"提取title生成词云\"\"\"\n",
    "        # 定义停用词集合\n",
    "        english_stopwords = set(stopwords.words('english'))\n",
    "        # 清洗和转换标题列\n",
    "        self.df['title'] = self.df['title'].astype(str)\n",
    "        # 提取英文标题并排除非英文内容\n",
    "        english_titles = self.df['title'].apply(lambda x: ' '.join([word.lower() for word in nltk.word_tokenize(x) if word.isalpha() and word.lower() not in english_stopwords]))\n",
    "        # 将所有英文标题合并为一个字符串\n",
    "        text = ' '.join(english_titles)\n",
    "        # 创建词云对象\n",
    "        wc = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "        wc.to_file(os.path.join(self.out_filepath, f'{self.filename}.jpg'))\n",
    "\n",
    "    def draw_wordsfrequency(self):\n",
    "        # 停用词列表\n",
    "        stop_words = ['a', 'an', 'and', 'or', 'in', 'on', 'for', 'with', 'the', 'using', 'based',\n",
    "                      'to', 'by', 'its', 'it', '&', 'as', 'via', 'base', 'improve', 'improved',]\n",
    "        # 分词并计算词频\n",
    "        word_counts = Counter(' '.join(self.df['title']).lower().split())\n",
    "        # 去除停用词\n",
    "        for stop_word in stop_words:\n",
    "            word_counts.pop(stop_word, None)\n",
    "        # 按照词频从高到低排序\n",
    "        sorted_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        # 提取词和频率\n",
    "        words = [item[0] for item in sorted_counts]\n",
    "        freqs = [item[1] for item in sorted_counts]\n",
    "\n",
    "        # 创建DataFrame保存词频数据\n",
    "        df_freq = pd.DataFrame({'Word': words, 'Frequency': freqs})\n",
    "        # 保存词频数据到Excel文件\n",
    "        df_freq.to_excel(os.path.join(self.out_filepath, 'word_frequency.xlsx'), index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    keywords = keywd\n",
    "    as_ylo = st_y\n",
    "    as_yhi = ed_y\n",
    "    max_pages = c_page\n",
    "    sort_bydate = isYear\n",
    "\n",
    "    out_filepath = '_'.join(keywords.replace('\"', '').replace(':', '').split())\n",
    "\n",
    "    scholar = Scholar(out_filepath)\n",
    "    scholar.start_browser(wait_time=60)\n",
    "    results = scholar.search(keywords, sort_bydate, as_ylo, as_yhi, max_pages=int(max_pages), delay=random.randint(0, 0))\n",
    "    scholar.close_browser()\n",
    "    scholar.save_file(nodup=True)\n",
    "\n",
    "\n",
    "    analyze = AnalyzeDraw(out_filepath)\n",
    "    analyze.draw_wordcloud()\n",
    "    analyze.draw_wordsfrequency()\n",
    "    print('>> all done <<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
